# -*- coding: utf-8 -*-
"""Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1221vokvs-QHMkwoqvssF6FDyvENyYyBz

## Packages/Library yang Digunakan
"""

from google.colab import drive
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split
from xgboost import XGBRegressor
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## Data Understanding

### Load Dataset & Data Understanding

Dataset PM2.5 Beijing diambil dari Google Drive dan dimuat menggunakan `pandas.read_csv()`. Dataset ini mencakup data observasi kualitas udara dari tahun 2010 hingga 2014.

Pada tahap ini juga dilakukan eksplorasi awal terhadap data:
- Melihat jumlah baris dan kolom
- Menampilkan contoh data
- Mengetahui distribusi nilai dan tipe data
- Mengecek missing values dan duplikat
- Mengevaluasi kemungkinan outlier
"""

drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/PRSA_data_2010.1.1-2014.12.31.csv')
data.head()

# Jumlah baris dan kolom
print(f"Jumlah baris dan kolom: {data.shape}")

# Informasi struktur data
data.info()

# Cek jumlah data duplikat (baris yang sama persis)
jumlah_duplikat = data.duplicated().sum()
print(f"Jumlah data duplikat: {jumlah_duplikat}")

# Jumlah nilai kosong per kolom
data.isnull().sum()

# Tampilkan semua nama kolom
print(data.columns)

sns.set(style="whitegrid")

# Plot distribusi target (pm2.5)
plt.figure(figsize=(10, 5))
sns.histplot(data['pm2.5'], bins=50, kde=True, color='skyblue')
plt.title('Distribusi PM2.5')
plt.xlabel('Konsentrasi PM2.5')
plt.ylabel('Jumlah Data')
plt.show()

"""Grafik diatas merupakan distribusi konsentrasi PM2.5 jelas menunjukkan distribusi yang right-skewed, artinya mayoritas nilai PM2.5 berada di kisaran rendah, tapi ada sebagian kecil data dengan nilai sangat tinggi (outlier).

## Data Preparation

### Data Cleaning

Nilai kosong pada kolom `pm2.5` dihapus karena terlalu banyak untuk diimputasi secara akurat.
"""

# Menghapus baris dengan nilai target (pm2.5) kosong
data = data.dropna(subset=['pm2.5'])

# Cek kembali jumlah missing value
data.isnull().sum()

# Gabungkan ke dalam kolom datetime
data['datetime'] = pd.to_datetime(data[['year', 'month', 'day', 'hour']])

# Atur datetime sebagai index (opsional untuk analisis waktu)
data.set_index('datetime', inplace=True)

"""### Encoding Fitur Kategorikal

Fitur `cbwd` (arah angin) dikonversi menjadi bentuk numerik menggunakan **one-hot encoding** agar dapat digunakan dalam model machine learning.

"""

# One-hot encoding untuk fitur kategorikal
data = pd.get_dummies(data, columns=['cbwd'])

"""### Feature Selection & Target

Fitur (X) yang digunakan mencakup semua fitur numerik dan hasil encoding, sedangkan target (y) adalah nilai `pm2.5`.
"""

# Pilih fitur yang akan digunakan (selain No, year, month, day, hour)
fitur_model = data.drop(columns=['No', 'year', 'month', 'day', 'hour'])

# Pisahkan antara fitur (X) dan target (y)
X = fitur_model.drop(columns=['pm2.5'])
y = fitur_model['pm2.5']

"""### Feature Scaling

Semua fitur numerik dinormalisasi menggunakan `StandardScaler` untuk memastikan model tidak bias terhadap fitur dengan skala besar.

"""

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""### Data Splitting

Dataset dibagi menjadi data latih dan data uji menggunakan `train_test_split` dari `sklearn`, dengan rasio 80:20.

"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

"""## Modelling & Evaluation

Tiga model machine learning digunakan:

1. **Linear Regression** – model baseline untuk prediksi linier sederhana.
2. **Random Forest Regressor** – model ensemble yang kuat terhadap overfitting dan menangani non-linearitas.
3. **XGBoost Regressor** – model boosting yang efisien, akurat, dan menjadi model terbaik di proyek ini.

Hyperparameter tuning dilakukan untuk Random Forest dan XGBoost menggunakan GridSearchCV atau RandomizedSearchCV.

Model dievaluasi menggunakan metrik:
- **MAE** (Mean Absolute Error)
- **RMSE** (Root Mean Squared Error)
- **R² Score**

Model XGBoost memiliki performa terbaik, dengan MAE paling rendah dan R² tertinggi (0.43).

"""

# Inisialisasi dan training
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Prediksi
y_pred_lr = lr_model.predict(X_test)

# Evaluasi
mae = mean_absolute_error(y_test, y_pred_lr)
rmse = np.sqrt(mean_squared_error(y_test, y_pred_lr))
r2 = r2_score(y_test, y_pred_lr)

print(f"Linear Regression MAE: {mae:.2f}")
print(f"Linear Regression RMSE: {rmse:.2f}")
print(f"Linear Regression R² Score: {r2:.2f}")

# Load data
data = pd.read_csv('/content/drive/MyDrive/PRSA_data_2010.1.1-2014.12.31.csv')

# Drop baris dengan nilai NaN
data = data.dropna()

# Fitur dan target
features = ['DEWP', 'TEMP', 'PRES', 'Iws', 'Is', 'Ir']
X = data[features]
y = data['pm2.5']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Regressor
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

# Prediksi
y_pred_rf = rf_model.predict(X_test)

# Evaluasi
mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest MAE: {mae_rf:.2f}")
print(f"Random Forest RMSE: {rmse_rf:.2f}")
print(f"Random Forest R² Score: {r2_rf:.2f}")

# Parameter grid untuk hyperparameter tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Inisialisasi model dan Grid Search
rf_model = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(
    estimator=rf_model,
    param_grid=param_grid,
    cv=3,
    scoring='neg_mean_squared_error',
    n_jobs=-1,
    verbose=1
)

# Fit model ke data latih
grid_search.fit(X_train, y_train)

# Model terbaik dari hasil Grid Search
best_rf = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Prediksi dengan model terbaik
y_pred_rf = best_rf.predict(X_test)

# Evaluasi performa model
mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Tuned RF MAE: {mae_rf:.2f}")
print(f"Tuned RF RMSE: {rmse_rf:.2f}")
print(f"Tuned RF R² Score: {r2_rf:.2f}")

xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=10, random_state=42)
xgb_model.fit(X_train, y_train)

y_pred_xgb = xgb_model.predict(X_test)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
r2_xgb = r2_score(y_test, y_pred_xgb)

print(f"XGBoost MAE: {mae_xgb:.2f}")
print(f"XGBoost RMSE: {rmse_xgb:.2f}")
print(f"XGBoost R² Score: {r2_xgb:.2f}")